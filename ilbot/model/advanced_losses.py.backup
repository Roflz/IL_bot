#!/usr/bin/env python3
"""
Advanced Loss Functions for OSRS Bot Training
Addresses event prediction issues with better class balancing and uncertainty handling
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Tuple, Optional, List
import numpy as np

class FocalLoss(nn.Module):
    """
    Focal Loss for addressing class imbalance in event classification
    Reduces the relative loss for well-classified examples and focuses on hard examples
    """
    
    def __init__(self, alpha: float = 1.0, gamma: float = 2.0, reduction: str = 'mean'):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction
    
    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss
        
        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss

class LabelSmoothingLoss(nn.Module):
    """
    Label Smoothing Loss for better generalization in event classification
    Prevents the model from being overconfident in its predictions
    """
    
    def __init__(self, classes: int, smoothing: float = 0.1, dim: int = -1):
        super().__init__()
        self.confidence = 1.0 - smoothing
        self.smoothing = smoothing
        self.cls = classes
        self.dim = dim
    
    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        pred = F.log_softmax(pred, dim=self.dim)
        with torch.no_grad():
            true_dist = torch.zeros_like(pred)
            true_dist.fill_(self.smoothing / (self.cls - 1))
            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)
        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))

class UncertaintyAwareLoss(nn.Module):
    """
    Uncertainty-Aware Loss that considers prediction confidence
    Encourages the model to be uncertain when it should be uncertain
    """
    
    def __init__(self, base_loss: nn.Module, uncertainty_weight: float = 0.1):
        super().__init__()
        self.base_loss = base_loss
        self.uncertainty_weight = uncertainty_weight
    
    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        # Base loss
        base_loss = self.base_loss(inputs, targets)
        
        # Uncertainty penalty - encourage appropriate uncertainty
        probs = F.softmax(inputs, dim=-1)
        max_probs = probs.max(dim=-1)[0]
        
        # Penalize overconfidence when wrong, encourage confidence when right
        uncertainty_penalty = torch.mean(
            torch.where(
                targets == probs.argmax(dim=-1),
                (1 - max_probs) ** 2,  # Encourage confidence when correct
                max_probs ** 2          # Penalize confidence when wrong
            )
        )
        
        return base_loss + self.uncertainty_weight * uncertainty_penalty

class AdvancedUnifiedEventLoss(nn.Module):
    """
    Advanced Unified Event Loss with multiple improvements:
    1. Focal Loss for event classification
    2. Label smoothing for better generalization
    3. Uncertainty-aware coordinate prediction
    4. Temporal consistency regularization
    5. Action sequence coherence
    """
    
    def __init__(self, 
                 data_config: Dict,
                 focal_alpha: float = 1.0,
                 focal_gamma: float = 2.0,
                 label_smoothing: float = 0.1,
                 uncertainty_weight: float = 0.1,
                 temporal_weight: float = 0.05,
                 coherence_weight: float = 0.03,
                 time_quantiles: list = [0.1, 0.5, 0.9]):
        super().__init__()
        
        self.data_config = data_config
        self.enum_sizes = data_config.get('enum_sizes', {})
        self.event_types = data_config.get('event_types', 4)
        
        # Advanced loss components
        self.focal_loss = FocalLoss(alpha=focal_alpha, gamma=focal_gamma)
        self.label_smoothing_loss = LabelSmoothingLoss(classes=self.event_types, smoothing=label_smoothing)
        
        # CRITICAL FIX: Add timing loss using PinballLoss
        from .losses import PinballLoss
        self.time_loss = PinballLoss(quantiles=time_quantiles, burst_aware=True)
        
        # PHASE 1: Add timing-aware loss functions
        self.timing_aware_loss = TimingAwareLoss(
            max_time=0.6,
            timing_weight=1.0,
            length_weight=1.0,
            coherence_weight=0.5
        )
        
        # Weights for different loss components
        self.uncertainty_weight = uncertainty_weight
        self.temporal_weight = temporal_weight
        self.coherence_weight = coherence_weight
        
        # Class weights for event classification
        self.register_buffer('event_class_weights', None)
        self.register_buffer('target_distribution', None)
        
        # Loss component tracking
        self.loss_components = {}
        
        # Debug flag
        self._debug_printed = False
        self._debug_derive_printed = False
    
    def set_event_class_weights(self, weights: torch.Tensor):
        """Set class weights for event classification"""
        self.register_buffer('event_class_weights', weights)
    
    def set_target_distribution(self, distribution: torch.Tensor):
        """Set target distribution for regularization"""
        self.register_buffer('target_distribution', distribution)
    
    def forward(self, 
                predictions: Dict[str, torch.Tensor],
                targets: torch.Tensor,
                valid_mask: torch.Tensor) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:
        """
        Compute advanced unified event loss
        
        Args:
            predictions: Model output dictionary
            targets: Target tensor [B, A, 7]
            valid_mask: Valid action mask [B, A]
        
        Returns:
            total_loss: Combined loss value
            loss_components: Dictionary of individual loss components
        """
        losses = {}
        
        # TEMPORARY: All specific losses set to zero for rebuilding (but with gradients)
        # Event Classification Losses
        losses['event_focal'] = self._compute_advanced_event_loss(predictions['event_logits'], targets, valid_mask)
        losses['event_label_smoothing'] = torch.tensor(0.0, device=targets.device, requires_grad=True)  # Combined in event_focal
        losses['event_class_weights'] = torch.tensor(0.0, device=targets.device, requires_grad=True)  # Combined in event_focal
        
        # Coordinate Losses
        losses['x_gaussian_nll'] = self._compute_uncertainty_aware_coordinate_loss(predictions, targets, valid_mask)
        losses['y_gaussian_nll'] = torch.tensor(0.0, device=targets.device, requires_grad=True)  # Combined in x_gaussian_nll
        losses['coordinate_uncertainty_penalty'] = torch.tensor(0.0, device=targets.device, requires_grad=True)  # Combined in x_gaussian_nll
        
        # Timing Losses
        losses['timing_pinball'] = self._compute_timing_prediction_loss(predictions, targets, valid_mask)
        losses['timing_burst_weighting'] = self._compute_timing_burst_weighting_loss(predictions, targets, valid_mask)
        
        # Temporal Consistency Losses
        losses['temporal_timing_jumps'] = self._compute_temporal_consistency_loss(predictions, targets, valid_mask)
        
        # Action Coherence Losses
        losses['coherence_transition_penalty'] = self._compute_action_coherence_loss(predictions, targets, valid_mask)
        
        # Uncertainty Regularization Losses
        uncertainty_loss = self._compute_uncertainty_regularization(predictions, valid_mask)
        losses['uncertainty_x_inf_penalty'] = uncertainty_loss  # Combined in uncertainty_regularization
        losses['uncertainty_y_inf_penalty'] = torch.tensor(0.0, device=targets.device, requires_grad=True)  # Combined in uncertainty_regularization
        losses['uncertainty_x_overconf_penalty'] = torch.tensor(0.0, device=targets.device, requires_grad=True)  # Combined in uncertainty_regularization
        losses['uncertainty_y_overconf_penalty'] = torch.tensor(0.0, device=targets.device, requires_grad=True)  # Combined in uncertainty_regularization
        losses['uncertainty_event_overconf_penalty'] = torch.tensor(0.0, device=targets.device, requires_grad=True)  # Combined in uncertainty_regularization
        
        # Sequence Length Loss - DISABLED (should emerge from timing naturally)
        losses['sequence_length'] = torch.tensor(0.0, device=targets.device, requires_grad=True)
        
        # Conditional losses also set to zero
        if self.target_distribution is not None:
            losses['distribution_kl_divergence'] = torch.tensor(0.0, device=targets.device, requires_grad=True)
        
        # PHASE 1: Add timing-aware losses (DISABLED - conflicting with basic timing loss)
        # timing_aware_losses = self.timing_aware_loss(predictions, targets, valid_mask)
        # losses.update(timing_aware_losses)
        
        # Combine all losses
        total_loss = sum(losses.values())
        
        # Store loss components for monitoring
        self.loss_components = losses
        
        return total_loss, losses
    
    def _compute_advanced_event_loss(self,
                                   event_logits: torch.Tensor,
                                   targets: torch.Tensor,
                                   valid_mask: torch.Tensor) -> torch.Tensor:
        """
        Compute advanced event classification loss using focal loss and label smoothing
        """
        # Derive event targets from action targets
        event_targets = self._derive_event_target(targets)
        

        
        # Apply valid mask
        valid_event_logits = event_logits[valid_mask]
        valid_event_targets = event_targets[valid_mask]
        
        if valid_event_logits.numel() == 0:
            return torch.tensor(0.0, device=event_logits.device)
        
        # Combine focal loss and label smoothing
        focal_loss = self.focal_loss(valid_event_logits, valid_event_targets)
        smooth_loss = self.label_smoothing_loss(valid_event_logits, valid_event_targets)
        
        # Weighted combination
        event_loss = 0.7 * focal_loss + 0.3 * smooth_loss
        
        # Apply class weights if available
        if self.event_class_weights is not None:
            # Ensure class weights are on the same device as targets
            class_weights = self.event_class_weights.to(valid_event_targets.device)[valid_event_targets]
            event_loss = (event_loss * class_weights).mean()
        
        return event_loss
    
    def _compute_uncertainty_aware_coordinate_loss(self,
                                                 predictions: Dict[str, torch.Tensor],
                                                 targets: torch.Tensor,
                                                 valid_mask: torch.Tensor) -> torch.Tensor:
        """
        Compute uncertainty-aware coordinate prediction loss
        """
        # Extract coordinate predictions and targets
        x_mu = predictions['x_mu']  # [B, A]
        y_mu = predictions['y_mu']  # [B, A]
        x_logsig = predictions['x_logsig']  # [B, A]
        y_logsig = predictions['y_logsig']  # [B, A]
        
        # Convert pixel coordinates to normalized coordinates (0-1 range)
        # Assuming screen resolution of 1920x1080 (typical for OSRS)
        x_target = targets[..., 1] / 1920.0  # [B, A] - normalize X
        y_target = targets[..., 2] / 1080.0  # [B, A] - normalize Y
        
        # Apply valid mask
        valid_x_mu = x_mu[valid_mask]
        valid_y_mu = y_mu[valid_mask]
        valid_x_logsig = x_logsig[valid_mask]
        valid_y_logsig = y_logsig[valid_mask]
        valid_x_target = x_target[valid_mask]
        valid_y_target = y_target[valid_mask]
        
        if valid_x_mu.numel() == 0:
            return torch.tensor(0.0, device=x_mu.device)
        
        # CRITICAL FIX: Only apply coordinate loss to actions with meaningful coordinates
        # Filter out actions where both x and y targets are zero (padding actions)
        meaningful_coords_mask = (valid_x_target > 0.001) | (valid_y_target > 0.001)
        
        if meaningful_coords_mask.sum() == 0:
            return torch.tensor(0.0, device=x_mu.device)
        
        # Apply meaningful coordinates mask
        meaningful_x_mu = valid_x_mu[meaningful_coords_mask]
        meaningful_y_mu = valid_y_mu[meaningful_coords_mask]
        meaningful_x_logsig = valid_x_logsig[meaningful_coords_mask]
        meaningful_y_logsig = valid_y_logsig[meaningful_coords_mask]
        meaningful_x_target = valid_x_target[meaningful_coords_mask]
        meaningful_y_target = valid_y_target[meaningful_coords_mask]
        
        # Gaussian NLL Loss for coordinates (only on meaningful coordinates)
        x_loss = F.gaussian_nll_loss(meaningful_x_mu, meaningful_x_target, torch.exp(meaningful_x_logsig))
        y_loss = F.gaussian_nll_loss(meaningful_y_mu, meaningful_y_target, torch.exp(meaningful_y_logsig))
        
        # Uncertainty penalty - encourage appropriate uncertainty
        x_uncertainty = torch.exp(meaningful_x_logsig)
        y_uncertainty = torch.exp(meaningful_y_logsig)
        
        # Penalize excessive uncertainty
        uncertainty_penalty = torch.mean(x_uncertainty + y_uncertainty)
        
        # Combine coordinate loss with uncertainty penalty
        coord_loss = x_loss + y_loss + self.uncertainty_weight * uncertainty_penalty
        
        # Debug: Print coordinate loss components if they're negative
        if coord_loss < 0:
            print(f"DEBUG: Negative coordinate loss detected!")
            print(f"  x_loss: {x_loss.item():.6f}")
            print(f"  y_loss: {y_loss.item():.6f}")
            print(f"  uncertainty_penalty: {uncertainty_penalty.item():.6f}")
            print(f"  total coord_loss: {coord_loss.item():.6f}")
            print(f"  x_mu range: [{valid_x_mu.min().item():.3f}, {valid_x_mu.max().item():.3f}]")
            print(f"  x_target range: [{valid_x_target.min().item():.3f}, {valid_x_target.max().item():.3f}]")
            print(f"  y_mu range: [{valid_y_mu.min().item():.3f}, {valid_y_mu.max().item():.3f}]")
            print(f"  y_target range: [{valid_y_target.min().item():.3f}, {valid_y_target.max().item():.3f}]")
        
        # Clamp negative losses to prevent training instability
        coord_loss = torch.clamp(coord_loss, min=0.0)
        
        return coord_loss
    
    def _compute_timing_prediction_loss(self,
                                      predictions: Dict[str, torch.Tensor],
                                      targets: torch.Tensor,
                                      valid_mask: torch.Tensor) -> torch.Tensor:
        """
        CRITICAL FIX: Compute timing prediction loss using PinballLoss
        This was completely missing, causing the model to never learn timing!
        """
        if 'time_q' not in predictions:
            return torch.tensor(0.0, device=targets.device)
        
        # Extract timing predictions and targets
        time_predictions = predictions['time_q']  # [B, A, 3] - quantiles (in seconds)
        time_targets = targets[..., 0] / 1000.0  # [B, A] - timing targets (convert ms to seconds)
        
        # CRITICAL FIX: PinballLoss expects [B, A, Q] format, not flattened
        # We need to pass the full tensors and let PinballLoss handle the masking internally
        if time_predictions.numel() == 0:
            return torch.tensor(0.0, device=time_predictions.device)
        
        # Use PinballLoss for quantile regression - pass the valid mask
        timing_loss = self.time_loss(time_predictions, time_targets, valid_mask)
        
        # Debug: Print timing loss details
        if timing_loss.item() > 0:
            print(f"DEBUG: Timing Pinball Loss = {timing_loss.item():.6f}")
            print(f"  time_predictions shape: {time_predictions.shape}")
            print(f"  time_targets shape: {time_targets.shape}")
            print(f"  valid_mask sum: {valid_mask.sum().item()}")
            print(f"  time_predictions range: [{time_predictions.min().item():.6f}, {time_predictions.max().item():.6f}]")
            print(f"  time_targets range: [{time_targets.min().item():.6f}, {time_targets.max().item():.6f}]")
        
        return timing_loss
    
    def _compute_timing_burst_weighting_loss(self,
                                           predictions: Dict[str, torch.Tensor],
                                           targets: torch.Tensor,
                                           valid_mask: torch.Tensor) -> torch.Tensor:
        """
        Compute timing burst weighting loss to encourage realistic timing patterns.
        This breaks constant timing predictions by weighting fast actions more heavily.
        """
        if 'time_q' not in predictions:
            return torch.tensor(0.0, device=targets.device)
        
        # Extract timing predictions and targets
        time_predictions = predictions['time_q']  # [B, A, 3] - quantiles (in seconds)
        time_targets = targets[..., 0] / 1000.0  # [B, A] - timing targets (convert ms to seconds)
        
        if time_predictions.numel() == 0:
            return torch.tensor(0.0, device=time_predictions.device)
        
        # Use median quantile (q0.5) for burst weighting
        median_predictions = time_predictions[:, :, 1]  # [B, A] - q0.5
        
        # Apply valid mask
        valid_predictions = median_predictions[valid_mask]
        valid_targets = time_targets[valid_mask]
        
        if valid_predictions.numel() == 0:
            return torch.tensor(0.0, device=median_predictions.device)
        
        # Burst-aware weighting: weight fast actions more heavily
        fast_threshold = 0.1  # 100ms
        slow_threshold = 1.0  # 1000ms
        
        # Create weights based on target values
        fast_mask = valid_targets <= fast_threshold
        slow_mask = valid_targets >= slow_threshold
        medium_mask = (valid_targets > fast_threshold) & (valid_targets < slow_threshold)
        
        # Weighting: fast=10.0, medium=1.0, slow=0.1
        weights = torch.ones_like(valid_targets)
        weights[fast_mask] = 10.0  # Heavily emphasize fast actions (94.5% of data)
        weights[medium_mask] = 1.0  # Normal weight for medium actions
        weights[slow_mask] = 0.1  # Minimize weight for slow actions (0.2% of data)
        
        # Compute weighted MSE loss
        diff = valid_predictions - valid_targets
        weighted_loss = torch.mean(weights * (diff ** 2))
        
        # Debug: Print timing burst weighting details
        if weighted_loss.item() > 0:
            print(f"DEBUG: Timing Burst Weighting Loss = {weighted_loss.item():.6f}")
            print(f"  valid_predictions range: [{valid_predictions.min().item():.6f}, {valid_predictions.max().item():.6f}]")
            print(f"  valid_targets range: [{valid_targets.min().item():.6f}, {valid_targets.max().item():.6f}]")
            print(f"  diff range: [{diff.min().item():.6f}, {diff.max().item():.6f}]")
            print(f"  weights range: [{weights.min().item():.6f}, {weights.max().item():.6f}]")
            print(f"  fast_mask count: {fast_mask.sum().item()}")
            print(f"  medium_mask count: {medium_mask.sum().item()}")
            print(f"  slow_mask count: {slow_mask.sum().item()}")
        
        return weighted_loss
    
    def _compute_temporal_consistency_loss(self,
                                         predictions: Dict[str, torch.Tensor],
                                         targets: torch.Tensor,
                                         valid_mask: torch.Tensor) -> torch.Tensor:
        """
        Compute temporal consistency loss to ensure smooth action sequences
        """
        if 'time_q' not in predictions:
            return torch.tensor(0.0, device=targets.device)
        
        time_predictions = predictions['time_q']  # [B, A, 3] - quantiles
        
        # Get median timing predictions
        median_times = time_predictions[:, :, 1]  # [B, A] - q0.5
        
        # Apply valid mask to get only valid actions
        valid_median_times = median_times * valid_mask.float()
        
        # Temporal consistency: consecutive actions within each sequence should have reasonable timing
        B, A = median_times.shape
        if A < 2:
            return torch.tensor(0.0, device=time_predictions.device)
        
        # Compute timing differences between consecutive actions within each sequence
        time_diffs = torch.diff(valid_median_times, dim=1)  # [B, A-1]
        
        # Only consider differences where both actions are valid
        valid_diffs_mask = valid_mask[:, :-1] & valid_mask[:, 1:]  # [B, A-1]
        
        if valid_diffs_mask.sum() == 0:
            return torch.tensor(0.0, device=time_predictions.device)
        
        # Apply mask to differences
        valid_time_diffs = time_diffs[valid_diffs_mask]
        
        # Debug: Print temporal consistency info
        if valid_time_diffs.numel() > 0:
            print(f"DEBUG: Temporal consistency - {valid_time_diffs.numel()} valid time diffs")
            print(f"  time_diffs range: [{valid_time_diffs.min().item():.6f}, {valid_time_diffs.max().item():.6f}]")
            print(f"  time_diffs mean: {valid_time_diffs.mean().item():.6f}")
            print(f"  time_diffs std: {valid_time_diffs.std().item():.6f}")
        
        # CRITICAL FIX: Penalize lack of timing variation to break constant predictions
        # The model is predicting almost constant timing (0.010s), we need to encourage variation
        timing_variance = torch.var(valid_time_diffs)
        timing_mean = torch.mean(valid_time_diffs)
        
        # Penalty for too little variation (encourages realistic timing patterns)
        variation_penalty = torch.exp(-timing_variance * 1000)  # Exponential penalty for low variance
        
        # Penalty for unrealistic timing jumps (original purpose)
        jump_penalty = torch.mean(torch.clamp(valid_time_diffs - 0.5, min=0.0) ** 2)
        
        # Combine penalties
        timing_penalty = variation_penalty + jump_penalty
        
        # Debug: Print temporal consistency details
        if timing_penalty.item() > 0:
            print(f"DEBUG: Temporal Consistency Loss = {timing_penalty.item():.6f}")
            print(f"  timing_variance: {timing_variance.item():.8f}")
            print(f"  timing_mean: {timing_mean.item():.6f}")
            print(f"  variation_penalty: {variation_penalty.item():.6f}")
            print(f"  jump_penalty: {jump_penalty.item():.6f}")
            print(f"  temporal_weight: {self.temporal_weight}")
        
        return self.temporal_weight * timing_penalty
    
    def _compute_sequence_length_loss(self,
                                    predictions: Dict[str, torch.Tensor],
                                    targets: torch.Tensor,
                                    valid_mask: torch.Tensor) -> torch.Tensor:
        """
        CRITICAL FIX: Compute sequence length prediction loss
        This was completely missing, causing the model to never learn how many actions to predict!
        """
        if 'sequence_length' not in predictions:
            return torch.tensor(0.0, device=targets.device)
        
        # Get predicted sequence lengths
        predicted_lengths = predictions['sequence_length']  # [B] - predicted number of actions per gamestate
        
        # Calculate actual sequence lengths from valid mask
        actual_lengths = valid_mask.sum(dim=1).float()  # [B] - actual number of valid actions per gamestate
        
        # Use MSE loss for sequence length prediction
        sequence_length_loss = F.mse_loss(predicted_lengths, actual_lengths)
        
        return sequence_length_loss
    
    def _compute_action_coherence_loss(self,
                                     predictions: Dict[str, torch.Tensor],
                                     targets: torch.Tensor,
                                     valid_mask: torch.Tensor) -> torch.Tensor:
        """
        Compute action coherence loss to ensure logical action sequences
        """
        if 'event_logits' not in predictions:
            return torch.tensor(0.0, device=targets.device)
        
        event_probs = F.softmax(predictions['event_logits'], dim=-1)  # [B, A, 4]
        
        # Action coherence: consecutive actions should make sense together
        B, A = event_probs.shape[:2]
        if B < 2 or A < 2:
            return torch.tensor(0.0, device=event_probs.device)
        
        # Get most likely events for each action
        predicted_events = event_probs.argmax(dim=-1)  # [B, A]
        
        # Analyze event transitions within each batch
        coherence_penalty = 0.0
        
        for b in range(B):
            batch_events = predicted_events[b]  # [A]
            valid_actions = valid_mask[b]  # [A]
            
            if valid_actions.sum() < 2:
                continue
            
            # Get valid event sequence
            valid_events = batch_events[valid_actions]
            
            if len(valid_events) < 2:
                continue
            
            # Penalize unrealistic event transitions
            for i in range(1, len(valid_events)):
                prev_event = valid_events[i-1]
                curr_event = valid_events[i]
                
                # Define unrealistic transitions
                unrealistic_transitions = [
                    (0, 0),  # CLICK -> CLICK (double click)
                    (1, 1),  # KEY -> KEY (double key press)
                    (2, 2),  # SCROLL -> SCROLL (double scroll)
                ]
                
                if (prev_event.item(), curr_event.item()) in unrealistic_transitions:
                    coherence_penalty += 1.0
        
        # Normalize by total valid actions
        total_valid = valid_mask.sum()
        if total_valid > 0:
            coherence_penalty = coherence_penalty / total_valid
        
        return self.coherence_weight * coherence_penalty
    
    def _compute_distribution_regularization(self,
                                           event_logits: torch.Tensor,
                                           valid_mask: torch.Tensor) -> torch.Tensor:
        """
        Compute distribution regularization to maintain target event distribution
        """
        if self.target_distribution is None:
            return torch.tensor(0.0, device=event_logits.device)
        
        # Get predicted probabilities
        event_probs = F.softmax(event_logits, dim=-1)  # [B, A, 4]
        
        # Average probabilities across valid actions
        if valid_mask.any():
            valid_probs = event_probs[valid_mask]
            avg_probs = valid_probs.mean(dim=0)  # [4]
        else:
            avg_probs = event_probs.mean(dim=(0, 1))  # [4]
        
        # Target distribution
        target_dist = self.target_distribution.to(event_probs.device)
        
        # KL divergence between predicted and target distribution
        eps = 1e-8
        avg_probs = avg_probs.clamp(min=eps)
        target_dist = target_dist.clamp(min=eps)
        
        kl_loss = (target_dist * torch.log(target_dist / avg_probs)).sum()
        
        return kl_loss
    
    def _compute_uncertainty_regularization(self,
                                          predictions: Dict[str, torch.Tensor],
                                          valid_mask: torch.Tensor) -> torch.Tensor:
        """
        Compute uncertainty regularization to prevent overconfidence
        """
        uncertainty_penalty = 0.0
        
        # Coordinate uncertainty regularization
        if 'x_logsig' in predictions and 'y_logsig' in predictions:
            x_uncertainty = torch.exp(predictions['x_logsig'])
            y_uncertainty = torch.exp(predictions['y_logsig'])
            
            # Penalize infinite or extremely large uncertainty
            x_inf_penalty = torch.isinf(x_uncertainty).float().sum()
            y_inf_penalty = torch.isinf(y_uncertainty).float().sum()
            
            # Penalize extremely small uncertainty (overconfidence)
            x_overconf_penalty = torch.mean(torch.clamp(1.0 - x_uncertainty, min=0.0) ** 2)
            y_overconf_penalty = torch.mean(torch.clamp(1.0 - y_uncertainty, min=0.0) ** 2)
            
            uncertainty_penalty += x_inf_penalty + y_inf_penalty + x_overconf_penalty + y_overconf_penalty
        
        # Event uncertainty regularization
        if 'event_logits' in predictions:
            event_probs = F.softmax(predictions['event_logits'], dim=-1)
            max_probs = event_probs.max(dim=-1)[0]
            
            # Penalize overconfidence in event predictions
            overconfidence_penalty = torch.mean(torch.clamp(max_probs - 0.9, min=0.0) ** 2)
            uncertainty_penalty += overconfidence_penalty
        
        return uncertainty_penalty
    
    def _derive_event_target(self, targets: torch.Tensor) -> torch.Tensor:
        """
        Derive event type from action targets with proper priority
        """
        B, A = targets.shape[:2]
        event_target = torch.full((B, A), 3, dtype=torch.long, device=targets.device)  # Default to MOVE
        
        # Extract action components
        button_target = targets[..., 3]  # Button column
        key_action_target = targets[..., 4]  # Key action column
        scroll_y_target = targets[..., 6]  # Scroll column
        

        
        # Priority order: CLICK > KEY > SCROLL > MOVE
        # SCROLL: scroll_y != 0 (lowest priority)
        scroll_mask = scroll_y_target != 0
        event_target[scroll_mask] = 2
        
        # KEY: key_action != 0 (medium priority - overwrites SCROLL)
        key_mask = key_action_target != 0
        event_target[key_mask] = 1
        
        # CLICK: button != 0 (highest priority - overwrites KEY and SCROLL)
        click_mask = button_target != 0
        event_target[click_mask] = 0
        
        return event_target
    
    def set_global_event_weights(self, event_targets: List[torch.Tensor], valid_masks: List[torch.Tensor]):
        """
        Set global event class weights based on dataset distribution
        Compatible with UnifiedEventLoss interface
        """
        # Flatten all event targets and valid masks
        all_events = []
        for events, mask in zip(event_targets, valid_masks):
            valid_events = events[mask]
            all_events.append(valid_events)
        
        if not all_events:
            return
        
        # Concatenate all valid events
        all_events = torch.cat(all_events, dim=0)
        
        # Count occurrences of each event type
        event_counts = torch.bincount(all_events, minlength=self.event_types)
        
        # Compute inverse frequency weights
        total_events = event_counts.sum()
        class_weights = total_events / (self.event_types * event_counts + 1e-8)
        
        # Normalize weights
        class_weights = class_weights / class_weights.sum()
        
        # Set the weights
        self.set_event_class_weights(class_weights)
        
        print(f"ðŸŽ¯ Set global event class weights: {class_weights.tolist()}")
    
    def reset_epoch_flag(self):
        """
        Reset epoch flag for loss function
        Compatible with UnifiedEventLoss interface
        """
        # Clear any epoch-specific state
        if hasattr(self, 'loss_components'):
            self.loss_components = {}
    
    def get_loss_breakdown(self) -> Dict[str, float]:
        """Get breakdown of loss components for monitoring"""
        return {k: v.item() if hasattr(v, 'item') else float(v) 
                for k, v in self.loss_components.items()}

class AdaptiveLossWeighting(nn.Module):
    """
    Adaptive loss weighting that automatically adjusts weights based on training progress
    """
    
    def __init__(self, base_loss: nn.Module, adaptation_rate: float = 0.01):
        super().__init__()
        self.base_loss = base_loss
        self.adaptation_rate = adaptation_rate
        
        # Track loss history for each component
        self.loss_history = {}
        self.weight_history = {}
        
        # Initialize adaptive weights
        self.adaptive_weights = nn.Parameter(torch.ones(1))
    
    def forward(self, *args, **kwargs):
        """Forward pass with adaptive weighting"""
        loss, components = self.base_loss(*args, **kwargs)
        
        # Update loss history
        for name, value in components.items():
            if name not in self.loss_history:
                self.loss_history[name] = []
            self.loss_history[name].append(value.item())
        
        # Adapt weights based on loss trends
        self._adapt_weights()
        
        # Apply adaptive weighting
        weighted_loss = loss * self.adaptive_weights
        
        return weighted_loss, components
    
    def _adapt_weights(self):
        """Adapt weights based on loss trends"""
        if len(self.loss_history) < 2:
            return
        
        # Calculate loss trends (simple moving average)
        trends = {}
        for name, history in self.loss_history.items():
            if len(history) >= 10:
                recent = history[-10:]
                trend = (recent[-1] - recent[0]) / len(recent)
                trends[name] = trend
        
        # Adjust weights based on trends
        if trends:
            # Increase weight for components with increasing loss
            # Decrease weight for components with decreasing loss
            total_trend = sum(trends.values())
            if total_trend != 0:
                adjustment = self.adaptation_rate * total_trend
                self.adaptive_weights.data += adjustment
                
                # Clamp weights to reasonable range
                self.adaptive_weights.data.clamp_(0.1, 10.0)
    
    def get_weight_history(self) -> Dict[str, List[float]]:
        """Get weight adaptation history"""
        return self.weight_history


class TimingAwareLoss(nn.Module):
    """
    Timing-aware loss that enforces 600ms constraints and cumulative timing logic.
    
    This loss addresses the fundamental issues with timing predictions:
    1. Ensures predicted times are cumulative and don't exceed 600ms
    2. Penalizes when sequence length doesn't match timing-derived length
    3. Enforces temporal coherence between actions
    """
    
    def __init__(self, max_time: float = 0.6, timing_weight: float = 1.0, 
                 length_weight: float = 1.0, coherence_weight: float = 0.5):
        super().__init__()
        self.max_time = max_time
        self.timing_weight = timing_weight
        self.length_weight = length_weight
        self.coherence_weight = coherence_weight
        
    def forward(self, predictions: Dict[str, torch.Tensor], 
                targets: torch.Tensor, 
                valid_mask: torch.Tensor) -> Dict[str, torch.Tensor]:
        """
        Compute timing-aware losses.
        
        Args:
            predictions: Model predictions including 'time_q' and 'sequence_length'
            targets: Target action sequences [B, A, F]
            valid_mask: Valid action mask [B, A]
            
        Returns:
            Dict of timing-aware losses
        """
        losses = {}
        
        # 1. Cumulative Timing Loss
        if 'time_q' in predictions:
            timing_loss = self._compute_cumulative_timing_loss(
                predictions['time_q'], targets, valid_mask
            )
            losses['cumulative_timing'] = timing_loss * self.timing_weight
        
        # 2. Sequence Length Consistency Loss
        if 'sequence_length' in predictions:
            length_loss = self._compute_sequence_length_consistency_loss(
                predictions, valid_mask
            )
            losses['sequence_length_consistency'] = length_loss * self.length_weight
        
        # 3. Temporal Coherence Loss
        if 'time_q' in predictions:
            coherence_loss = self._compute_temporal_coherence_loss(
                predictions['time_q'], valid_mask
            )
            losses['temporal_coherence'] = coherence_loss * self.coherence_weight
        
        return losses
    
    def _compute_cumulative_timing_loss(self, time_predictions: torch.Tensor, 
                                      targets: torch.Tensor, 
                                      valid_mask: torch.Tensor) -> torch.Tensor:
        """
        Compute cumulative timing loss that enforces 600ms constraint.
        
        Args:
            time_predictions: [B, A, 3] - quantile predictions (q0.1, q0.5, q0.9)
            targets: [B, A, F] - target actions (column 0 is timing)
            valid_mask: [B, A] - valid action mask
        """
        # Use median quantile (q0.5) for timing predictions
        median_times = time_predictions[:, :, 1]  # [B, A] - q0.5
        
        # Apply valid mask
        valid_times = median_times * valid_mask.float()
        
        # Compute cumulative timing
        cumulative_times = torch.cumsum(valid_times, dim=1)  # [B, A]
        
        # Penalize exceeding 600ms window
        exceed_mask = cumulative_times > self.max_time  # [B, A]
        exceed_penalty = torch.sum((cumulative_times - self.max_time) * exceed_mask.float())
        
        # Also penalize if cumulative times are too small (unrealistic)
        min_time_penalty = torch.sum(torch.clamp(0.01 - cumulative_times, min=0.0))
        
        return exceed_penalty + min_time_penalty
    
    def _compute_sequence_length_consistency_loss(self, predictions: Dict[str, torch.Tensor], 
                                                valid_mask: torch.Tensor) -> torch.Tensor:
        """
        Compute sequence length consistency loss.
        
        Args:
            predictions: Model predictions
            valid_mask: [B, A] - valid action mask
        """
        if 'time_q' not in predictions or 'sequence_length' not in predictions:
            return torch.tensor(0.0, device=valid_mask.device)
        
        # Get predicted sequence length
        predicted_lengths = predictions['sequence_length']  # [B, 1]
        
        # Derive sequence length from timing predictions
        median_times = predictions['time_q'][:, :, 1]  # [B, A] - q0.5
        valid_times = median_times * valid_mask.float()
        cumulative_times = torch.cumsum(valid_times, dim=1)  # [B, A]
        
        # Count actions that fit within 600ms
        timing_derived_lengths = (cumulative_times <= self.max_time).sum(dim=1, keepdim=True).float()
        
        # Compute consistency loss
        length_consistency_loss = F.mse_loss(predicted_lengths, timing_derived_lengths)
        
        return length_consistency_loss
    
    def _compute_temporal_coherence_loss(self, time_predictions: torch.Tensor, 
                                       valid_mask: torch.Tensor) -> torch.Tensor:
        """
        Compute temporal coherence loss to ensure realistic timing patterns.
        
        Args:
            time_predictions: [B, A, 3] - quantile predictions
            valid_mask: [B, A] - valid action mask
        """
        # Use median quantile for coherence
        median_times = time_predictions[:, :, 1]  # [B, A]
        
        # Apply valid mask
        valid_times = median_times * valid_mask.float()
        
        # Penalize unrealistic timing patterns
        # 1. Actions should have reasonable intervals (not too fast, not too slow)
        too_fast_penalty = torch.sum(torch.clamp(0.01 - valid_times, min=0.0))  # < 10ms
        too_slow_penalty = torch.sum(torch.clamp(valid_times - 2.0, min=0.0))   # > 2s
        
        # 2. Timing should be somewhat consistent (not wildly varying)
        # Compute variance in timing within each sequence
        timing_variance = torch.var(valid_times, dim=1, keepdim=True)  # [B, 1]
        variance_penalty = torch.mean(timing_variance)
        
        return too_fast_penalty + too_slow_penalty + variance_penalty


class CumulativeTimingLoss(nn.Module):
    """
    Loss function that enforces cumulative timing logic.
    
    This loss ensures that timing predictions are cumulative from the start
    of the 600ms window, not independent deltas.
    """
    
    def __init__(self, max_time: float = 0.6, weight: float = 1.0):
        super().__init__()
        self.max_time = max_time
        self.weight = weight
        
    def forward(self, time_predictions: torch.Tensor, 
                target_times: torch.Tensor, 
                valid_mask: torch.Tensor) -> torch.Tensor:
        """
        Compute cumulative timing loss.
        
        Args:
            time_predictions: [B, A, 3] - quantile predictions
            target_times: [B, A] - target timing (cumulative from start)
            valid_mask: [B, A] - valid action mask
        """
        # Use median quantile for loss computation
        predicted_times = time_predictions[:, :, 1]  # [B, A] - q0.5
        
        # Apply valid mask
        valid_predicted = predicted_times * valid_mask.float()
        valid_targets = target_times * valid_mask.float()
        
        # Compute cumulative timing for predictions
        cumulative_predicted = torch.cumsum(valid_predicted, dim=1)  # [B, A]
        
        # Target times should already be cumulative
        cumulative_targets = valid_targets  # [B, A]
        
        # Compute loss between cumulative predictions and targets
        timing_loss = F.mse_loss(cumulative_predicted, cumulative_targets)
        
        # Additional penalty for exceeding max time
        exceed_mask = cumulative_predicted > self.max_time
        exceed_penalty = torch.sum((cumulative_predicted - self.max_time) * exceed_mask.float())
        
        return self.weight * (timing_loss + exceed_penalty)
